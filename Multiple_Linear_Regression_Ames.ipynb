{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict selling price of houses in Ames, Iowa by using machine learning techniques (Multiple Linear Regression, SVR, Decision Tree, Decision Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of inputs: **1461**\n",
    "- Number of variables: **79**\n",
    "- Dataset: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "- Data fields description: can be found here \"data_description.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ames_1.csv')\n",
    "df = df.drop(df.columns[0], axis=1) #deleting the id column\n",
    "df = df.fillna(0) # replacing NaN with zeros, needed for onehotencoder, NaN is not accepted\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].astype(float).values #last column are prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of categorical variables and encoding them with LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [0,1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,20,\n",
    "            21,22,23,24,26,27,28,29,30,31,32,34,\n",
    "            38,39,40,41,52,54,56,57,59,62,63,64,71,72,73,77,78]\n",
    "#selection was done manually because some categorical variables are numerical, some are strings\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder() \n",
    "for i in col_list:\n",
    "    df.iloc[:, i] = labelencoder.fit_transform(df.iloc[:, i].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of continious variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cat_var = []\n",
    "for el in range(len(df.columns)-1):         #excluding variable that we are predicting\n",
    "    if el in col_list:\n",
    "        continue\n",
    "    else:\n",
    "        no_cat_var.append(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a reference dictionary to find corresponding variables after OneHotEncoding in the initial dataframe\n",
    "This dictionary can be used to find corresponding variables that were chosen by \"Forward Selection\" and \"Backward Elimination\" further below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dict = {}\n",
    "dict_iter=0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables with OneHotEncoder\n",
    "The first categorical column will be encoded, result will be added separately in a ndarray, ecluding first dummy column. All other categorical columns will be encoded and added to this ndarray afterwards via loop. That allows to use OneHotEncoder on range of categorical variables without manually encoding one variable after another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical = df.iloc[:, col_list]                           #df with categorical variables\n",
    "\n",
    "X_cat = df_categorical.iloc[:, :].values                        #categorical ndarray\n",
    "X_cat[:, 0] = labelencoder.fit_transform(X_cat[:, 0])           \n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])       #encoding 1st column\n",
    "X_cc = onehotencoder.fit_transform(X_cat).toarray()              \n",
    "dummy_col = df_categorical.iloc[:, 0].nunique()                 #finding out number of dummy colummns created\n",
    "\n",
    "X_cc_2 = X_cc[:, 1:dummy_col]                                   #moving to a separate ndarray excluding first dummy column\n",
    "\n",
    "df_cat_no_one = df_categorical.iloc[:, 1:]                      #first column was preprocessed so it was excuded from further loop\n",
    "X_cat_no_one = df_cat_no_one.iloc[:, :].values\n",
    "\n",
    "ref_dict[0] = list(range(dict_iter, dict_iter+dummy_col))     #adding id of original column as key, all corresponding dummy columns as list\n",
    "dict_iter = dict_iter + dummy_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first column was encoded in dummy variables and they were added to separate ndarray. <br>\n",
    "Other encoded variables will be added to this ndarray via loop below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding other categorical variables to ndarray via loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_iter=0 \n",
    "for c in range(len(col_list)-1):\n",
    "    X_cat_no_one[:, c] = labelencoder.fit_transform(X_cat_no_one[:, c])           \n",
    "    onehotencoder = OneHotEncoder(categorical_features = [c])\n",
    "    X_cc = onehotencoder.fit_transform(X_cat_no_one).toarray()                    \n",
    "    dummy_col = df_categorical.iloc[:, c+1].nunique()                             #+1 because of reffering to df with all categorical variables, including the first one\n",
    "    X_cc2_2 = X_cc[:, 1:dummy_col]                                                #excluding first dummy column\n",
    "    X_cc_2 = np.concatenate((X_cc_2, X_cc2_2), axis=1)                            #merge 2 ndarrays\n",
    "    ref_dict[c+1] = list(range(dict_iter, dict_iter+dummy_col))                   #adding id of original column as key, all corresponding dummy columns as list\n",
    "    dict_iter = dict_iter + dummy_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After that all continious variables are added to a ndarray with encoded categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_categorical = df.iloc[:, no_cat_var]\n",
    "X_no_cat_var = df_non_categorical.iloc[:, :].values\n",
    "merged_dataset = np.concatenate((X_cc_2, X_no_cat_var), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataset to work with\n",
    "296 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns to work with\n",
    "At this point there are 296 columns to choose from for a machine learning model. A subjective selection is not appropriate so two approaches will be used to select a required range of variables for machine learning algorithm. These approaches are \"Backward Elimination\" and \"Forward selection\": https://en.wikipedia.org/wiki/Stepwise_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with <b>Backward Elimination<b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "p=0.05\n",
    "\n",
    "#imputs for def are: dataset and p-value\n",
    "def BackwardElimination(merged_dataset, p):\n",
    "    merged_dataset = np.append(arr = np.ones((np.size(merged_dataset,0),1)).astype(int), values=merged_dataset, axis=1) #np.size(merged_categ,0) - number of rows in numpy array\n",
    "    #this adds our dataset to a column of one so ones are in the first column\n",
    "\n",
    "    #number of columns\n",
    "    len_list = []                                 #list of indexes of all columns\n",
    "    for i in range(np.size(merged_dataset,1)+1):\n",
    "        len_list.append(i)\n",
    "\n",
    "    \n",
    "    p = p #p-value for; can be adjusted depending on desired result (default - 0.05)\n",
    "\n",
    "    end = False\n",
    "    while end==False:\n",
    "        regressor_OLS = sm.OLS(endog = y, exog = merged_dataset).fit()\n",
    "        p_values = regressor_OLS.pvalues\n",
    "        #enable these prints to see a process of selection in a real time\n",
    "        #print(\"P values are: \"+str(['%.3f' % i for i in p_values.tolist()]))\n",
    "        #print(\"Max p value: \"+str(max(p_values)))\n",
    "        #print(\"==============================================\")\n",
    "        if max(p_values)<p:\n",
    "            end = True\n",
    "            return merged_dataset\n",
    "        elif max(p_values)>=p:\n",
    "            p_max_pos = p_values.tolist().index(max(p_values))\n",
    "            merged_dataset = np.delete(merged_dataset, [p_max_pos], axis=1)\n",
    "\n",
    "X = BackwardElimination(merged_dataset, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression with cross-validation (Backward Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score for r^2=[0.78636832 0.91921861 0.9122908 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor_back = LinearRegression()\n",
    "regressor_back.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor_back.predict(X_test)\n",
    "\n",
    "r2_scores = cross_val_score(regressor_back, X_train, y_train, scoring='r2', cv=3)\n",
    "print('Cross-validation score for r^2={}'.format(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of Linear Regression<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.570934689084265"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of Linear Regression<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2963060661.942607"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of Linear Regression<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19686.99444786974"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=[]\n",
    "mse=[]\n",
    "r2=[]\n",
    "mae=[]\n",
    "\n",
    "model_name.append(\"Backward/MLR\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (RBF kernel) (Backward Elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train test split and Feature Scaling<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #X_train.reshape(-1, 1) is added because there is only one column\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = sc_y.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using GridSearch to find the best combination of C and gamma<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.0001, 0.001, 0.01, 0.1, 1, 2] \n",
    "param_grid = dict(gamma=gammas, C=Cs)\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svr = SVR(kernel='rbf')\n",
    "grid_search = GridSearchCV(svr, param_grid)\n",
    "\n",
    "#fit best combination of parameters\n",
    "grid_search.fit(X_train, y_train.ravel()) #ravel is needed to convert int to float\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. accuracy): ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (accuracy):  0.9094093728337792\n"
     ]
    }
   ],
   "source": [
    "print('Grid best score (accuracy): ', grid_search.best_score_) #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of SVR<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7680587755446528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of SVR<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2319412244553471"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of SVR<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21544819542982774"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Backward/SVR\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with cross-validation and GridSearch (Backward Elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train test split and Feature Scaling<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #X_train.reshape(-1, 1) is added because there is only one column\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = sc_y.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using GridSearch to find the best combination of parameters<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = np.linspace(1, 40, 40, endpoint=True)\n",
    "\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dec_tree = DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(dec_tree, param_grid)\n",
    "\n",
    "#fit best combination of parameters\n",
    "grid_search.fit(X_train, y_train.ravel()) #ravel is needed to convert int to float\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'max_depth': 9.0}\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. accuracy): ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (accuracy):  0.7326437511733014\n"
     ]
    }
   ],
   "source": [
    "print('Grid best score (accuracy): ', grid_search.best_score_) #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of Decision Tree<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7646343334387243"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of Decision Tree<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23536566656127567"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of Decision Tree<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3132771151905251"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Backward/Decision Tree\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train test split and Feature Scaling<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #X_train.reshape(-1, 1) is added because there is only one column\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = sc_y.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using GridSearch to find the best combination of parameters<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "max_depth = np.linspace(1, 40, 40, endpoint=True)\n",
    "n_estimators = [5,10,15,20,30]\n",
    "\n",
    "param_grid = dict(max_depth=max_depth, n_estimators = n_estimators)\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "forest = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest, param_grid)\n",
    "\n",
    "#fit best combination of parameters\n",
    "grid_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'max_depth': 32.0, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. accuracy): ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (accuracy):  0.857532073745342\n"
     ]
    }
   ],
   "source": [
    "print('Grid best score (accuracy): ', grid_search.best_score_) #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of Decision Forest<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8256867368203639"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of Decision Forest<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1743132631796361"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of Decision Forest<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23992240987487665"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Backward/Random Forest\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets apply <b>Forward Selection<b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "y = df.iloc[:, -1].astype(float).values\n",
    "\n",
    "def ForwardSelection(merged_dataset, p):\n",
    "    unknown_variables = []                  #a list of variables that are not included as \"good\" ones; after each iteration some variable dissapears from \"unknown\" and becomes \"good\"\n",
    "    for i in range(merged_dataset.shape[1]):\n",
    "        unknown_variables.append(i)\n",
    "    \n",
    "    #adding b0 variable from formula\n",
    "    merged_dataset = np.append(arr = np.ones((np.size(merged_dataset,0),1)).astype(int), values=merged_dataset, axis=1) #np.size(merged_categ,0) - number of rows in numpy array\n",
    "    p = p\n",
    "    \n",
    "    ###first iteration is added separately, others in a loop below\n",
    "    p_values_list=[]\n",
    "    good_variables=[]\n",
    "    for i in range(merged_dataset.shape[1]):\n",
    "        X_opt = merged_dataset[:, i]\n",
    "        regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()   #finding p value of every variable and y(the variable to predict)\n",
    "        p_value = regressor_OLS.pvalues\n",
    "        p_values_list.extend(p_value.tolist())\n",
    "    min_p_value = min(p_values_list)                            #finding the minimum p value\n",
    "    min_index = p_values_list.index(min_p_value)                #variable with the smallest p value\n",
    "    good_variables.append(min_index)                            #add a variable to a \"good\" list\n",
    "    unknown_variables.remove(min_index)                         #remove index from a list of \"bad\" variables\n",
    "    \n",
    "    end=False\n",
    "    while end==False:\n",
    "        comb_list = []\n",
    "        p_values_list=[]\n",
    "        \n",
    "        #this loop exists to make combinations of \"good\" variables with every \"unknown\" to find p value of every combination\n",
    "        for i in unknown_variables:                            \n",
    "            temp_list = []\n",
    "            for t in good_variables:\n",
    "                temp_list.append(t)\n",
    "            temp_list.append(i)\n",
    "            comb_list.append([temp_list])\n",
    "            #print(temp_list)\n",
    "        for el in comb_list:\n",
    "            X_opt = merged_dataset[:, el[0]]\n",
    "            regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "            p_value = regressor_OLS.pvalues\n",
    "            pvalue_lst = p_value.tolist()\n",
    "            p_values_list.append(pvalue_lst[-1])\n",
    "        #finding combination with min p value\n",
    "        min_p_value = min(p_values_list)                            \n",
    "        min_index = p_values_list.index(min_p_value)\n",
    "        good_variables.append(comb_list[min_index][-1][-1])\n",
    "        unknown_variables.remove(comb_list[min_index][-1][-1])\n",
    "        #uncomment to see every step\n",
    "        #print(\"Min p value: \"+str(min_p_value))\n",
    "        #print(\"List of variables: \"+str(good_variables))\n",
    "        #print(\"####################################\")\n",
    "        if min_p_value>p:\n",
    "             end=True\n",
    "        \n",
    "    #print(\"UN: \"+str(unknown_variables))\n",
    "    print(\"GN: \"+str(good_variables))\n",
    "    return merged_dataset[:, good_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GN: [0, 269, 259, 159, 265, 279, 275, 93, 92, 85, 70, 235, 40, 168, 91, 264, 1, 249, 49, 99, 258, 100, 98, 101, 56, 50, 286, 234, 233, 243, 255, 206, 113, 55, 116, 60, 277, 77, 260, 261, 37, 285, 107, 97, 76, 173, 29, 19, 268, 41, 112, 119, 170, 22, 108, 158, 284, 276, 274, 270, 272, 228, 210, 186, 17]\n"
     ]
    }
   ],
   "source": [
    "p = 0.05\n",
    "X = ForwardSelection(merged_dataset, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression via cross-validation (Forward Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score for^2=[0.78110129 0.91666683 0.89260419]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "r2_scores = cross_val_score(regressor, X_train, y_train, scoring='r2', cv=3)\n",
    "print('Cross-validation score for^2={}'.format(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of Linear Regression<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6605208927634301"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of Linear Regression<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344391780.489629"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of Linear Regression<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19278.979224686384"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Forward/MLR\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (RBF kernel) (Forward Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train test split and Feature Scaling<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #X_train.reshape(-1, 1) is added because there is only one column\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = sc_y.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using GridSearch to find the best combination of C and gamma<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.0001, 0.001, 0.01, 0.1, 1, 2] \n",
    "param_grid = dict(gamma=gammas, C=Cs)\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svr = SVR(kernel='rbf')\n",
    "grid_search = GridSearchCV(svr, param_grid)\n",
    "\n",
    "#fit best combination of parameters\n",
    "grid_search.fit(X_train, y_train.ravel()) #ravel is needed to convert int to float\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. accuracy): ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (accuracy):  0.9012570709150719\n"
     ]
    }
   ],
   "source": [
    "print('Grid best score (accuracy): ', grid_search.best_score_) #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of SVR<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759773373113279"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of SVR<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24022662688672103"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of SVR<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21734930595806085"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Forward/SVR\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with cross-validation and GridSearch (Forward Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train test split and Feature Scaling<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #X_train.reshape(-1, 1) is added because there is only one column\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = sc_y.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using GridSearch to find the best combination of parameters<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = np.linspace(1, 40, 40, endpoint=True)\n",
    "\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dec_tree = DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(dec_tree, param_grid)\n",
    "\n",
    "#fit best combination of parameters\n",
    "grid_search.fit(X_train, y_train.ravel()) #ravel is needed to convert int to float\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'max_depth': 8.0}\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. accuracy): ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (accuracy):  0.7363753120652549\n"
     ]
    }
   ],
   "source": [
    "print('Grid best score (accuracy): ', grid_search.best_score_) #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared of Decision tree<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534796402230192"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE of Decision tree<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24652035977698084"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of Decision Tree<b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33652024310605166"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Forward/Decision Tree\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train test split and Feature Scaling<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #X_train.reshape(-1, 1) is added because there is only one column\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = sc_y.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using GridSearch to find the best combination of parameters<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "max_depth = np.linspace(1, 40, 40, endpoint=True)\n",
    "n_estimators = [5,10,15,20,30]\n",
    "\n",
    "param_grid = dict(max_depth=max_depth, n_estimators = n_estimators)\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "forest = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest, param_grid)\n",
    "\n",
    "#fit best combination of parameters\n",
    "grid_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'max_depth': 20.0, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. accuracy): ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (accuracy):  0.8610798031811986\n"
     ]
    }
   ],
   "source": [
    "print('Grid best score (accuracy): ', grid_search.best_score_) #train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-squared<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449653911665643"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MSE<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15503460883343567"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAE of Decision Tree<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23708490356253453"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding results to a table for summarization in the end</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append(\"Forward/Random Forest\")\n",
    "mae.append(mean_absolute_error(y_test, y_pred))\n",
    "r2.append(r2_score(y_test, y_pred))\n",
    "mse.append(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward/MLR</td>\n",
       "      <td>2.963061e+09</td>\n",
       "      <td>0.571</td>\n",
       "      <td>19686.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backward/SVR</td>\n",
       "      <td>2.320000e-01</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backward/Decision Tree</td>\n",
       "      <td>2.350000e-01</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Backward/Random Forest</td>\n",
       "      <td>1.740000e-01</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forward/MLR</td>\n",
       "      <td>2.344392e+09</td>\n",
       "      <td>0.661</td>\n",
       "      <td>19278.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward/SVR</td>\n",
       "      <td>2.400000e-01</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Forward/Decision Tree</td>\n",
       "      <td>2.470000e-01</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forward/Random Forest</td>\n",
       "      <td>1.550000e-01</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name           mse     r2        mae\n",
       "0            Backward/MLR  2.963061e+09  0.571  19686.994\n",
       "1            Backward/SVR  2.320000e-01  0.768      0.215\n",
       "2  Backward/Decision Tree  2.350000e-01  0.765      0.313\n",
       "3  Backward/Random Forest  1.740000e-01  0.826      0.240\n",
       "4             Forward/MLR  2.344392e+09  0.661  19278.979\n",
       "5             Forward/SVR  2.400000e-01  0.760      0.217\n",
       "6   Forward/Decision Tree  2.470000e-01  0.753      0.337\n",
       "7   Forward/Random Forest  1.550000e-01  0.845      0.237"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'model_name': model_name, 'mse': mse, 'r2': r2,\n",
    "'mae': mae}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, **Random Forest** achieved the best r-squared among all models as well as the best MSE. As of the feature selection approach, **Forward Selection** did better for Random Forst, but worse for SVR and Decision Tree. The worst model in linear regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
